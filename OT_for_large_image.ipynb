{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,urllib.request\n",
    "import numpy as np,codecs\n",
    "s=os.getcwd()\n",
    "s=s+\"\\\\mnist\\\\\"\n",
    "\n",
    "files=os.listdir(s)\n",
    "\n",
    "def gint(b):\n",
    "    return int(codecs.encode(b,'hex'),16)\n",
    "\n",
    "dic={}\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('ubyte'):\n",
    "        print('Reading',file)\n",
    "        with open(s+file,'rb') as f:\n",
    "            data=f.read()\n",
    "            mnam=gint(data[:4])\n",
    "            nosam=gint(data[4:8])\n",
    "            if mnam==2049:\n",
    "                cat='label'\n",
    "                parsed=np.frombuffer(data,dtype=np.uint8,offset=8)\n",
    "                parsed=parsed.reshape(nosam)\n",
    "                print(parsed)\n",
    "            elif mnam==2051:\n",
    "                cat='Image'\n",
    "                nor=gint(data[8:12])\n",
    "                noc=gint(data[12:16])\n",
    "                parsed=np.frombuffer(data,dtype=np.uint8,offset=16)\n",
    "                parsed=parsed.reshape(nosam,nor,noc)\n",
    "            if nosam==10000:\n",
    "                e='test'\n",
    "            else:\n",
    "                e='train'\n",
    "            dic[cat+'_'+e]=parsed\n",
    "#print(dic['Image_test'][0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "#cv.imwrite('temp.jpg',dic['Image_test'][0])\n",
    "cv.imshow('Image',dic['Image_test'][1000])\n",
    "#print(type(int(dic['Image_test'][9])))\n",
    "cv.waitKey(0);\n",
    "cv.destroyAllWindows();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dic['Image_test'][1000].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math,random\n",
    "z={}\n",
    "for i in range(len(dic['Image_test'])):\n",
    "    z[i]=np.zeros((56,56),dtype='uint8')\n",
    "    a=1\n",
    "    im=cv.resize(dic['Image_test'][i],((math.floor(a*28),math.floor(a*28))))\n",
    "    e=56-math.floor(a*28)\n",
    "    w=math.floor(e*np.random.random((1)))\n",
    "    h=math.floor(e*np.random.random((1)))\n",
    "    z[i][w:w+56-e,h:h+56-e]=im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(1000,1006):\n",
    "    plt.imshow(z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "typ=['train','test']\n",
    "for t in typ:\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i in range(len(dic['Image_'+t])):\n",
    "        z=np.zeros((1,56,56),dtype='uint8')\n",
    "        a=1\n",
    "        l=dic['label_'+t][i]\n",
    "        im=cv.resize(dic['Image_'+t][i],((math.floor(a*28),math.floor(a*28))))\n",
    "        e=56-math.floor(a*28)\n",
    "        w=math.floor(e*np.random.random((1)))\n",
    "        h=math.floor(e*np.random.random((1)))\n",
    "        z[0,w:w+56-e,h:h+56-e]=im\n",
    "        x.append(z)\n",
    "        y.append(l)\n",
    "    np.save(t+'_data.npy',np.asarray(x))\n",
    "    np.save(t+'_label.npy',np.asarray(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic['label_train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "class GridDataset(Dataset):\n",
    "  def __init__(self,type):\n",
    "    s = os.getcwd()\n",
    "    self.x=[]\n",
    "    self.y=[]\n",
    "    self.x=np.load(type+\"_data.npy\", allow_pickle=True)\n",
    "    self.y=np.load(type+'_label.npy',allow_pickle=True)\n",
    "    self.x=torch.from_numpy(self.x/255).float()\n",
    "    self.y=torch.from_numpy(self.y).float()\n",
    "\n",
    "  def __getitem__(self,index):\n",
    "    return self.x[index], self.y[index]\n",
    "  def __len__(self):\n",
    "    return self.x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.309844\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.298390\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.316203\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.303821\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.301211\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.267508\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.282256\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.235485\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.221292\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.187207\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.076581\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.335712\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.119597\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.127778\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.900096\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.937241\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.254881\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.779628\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.882846\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.479203\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.870984\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.779612\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.317731\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.804188\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.744115\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.400215\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1.508152\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 1.772097\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.490886\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 1.486549\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.404579\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 1.471244\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 1.347137\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 1.684051\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 1.359172\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 1.145298\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 1.213236\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 1.196726\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 1.424787\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 1.408569\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.192055\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 1.316274\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 1.118068\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 1.376916\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 1.226435\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 1.315790\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 1.361820\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 1.391695\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 1.426942\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 1.141725\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.019935\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 1.247983\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 1.100722\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 1.052078\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 1.151601\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 1.212922\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.936135\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 1.288997\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 1.526469\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 1.152450\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.092091\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 1.284319\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 1.424670\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 1.189822\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 1.007673\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 1.251576\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 1.066617\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 1.090373\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 1.113767\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.806967\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.177812\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.839823\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 1.098722\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 1.023525\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 1.077965\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.035944\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.781936\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 1.095323\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.979756\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 1.138468\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.384720\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 1.195092\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.790982\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 1.177575\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.975317\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 1.109237\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.823768\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 1.040089\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 1.044776\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.759572\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.683599\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.928220\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.885938\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.804413\n",
      "\n",
      "Test set: Average loss: 0.4704, Accuracy: 8685/10000 (87%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.645274\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.599327\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.573925\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.956110\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.905916\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.657671\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.882980\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.716332\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.581965\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.477558\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.589303\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 1.090422\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.750942\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.804736\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.754206\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.780953\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.622198\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.798675\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.778981\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.589121\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.564620\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.568718\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.900831\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.692196\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.703475\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.531736\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.610342\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.541478\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.758783\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.830566\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.832818\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.585421\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.599155\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.734927\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.682931\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.710041\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.596637\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.862647\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 1.351603\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.560407\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.862658\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.674884\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.632706\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.804491\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.651011\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.618986\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.386644\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.763224\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.736784\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.508520\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.611146\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 1.113715\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.672825\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.656114\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.546692\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.502805\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.659644\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.659823\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.562933\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.542630\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.544444\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.444662\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.617244\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.623127\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.878120\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.519718\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.580515\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.639485\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.623907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.768881\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.670069\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.400160\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.643294\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.443497\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.607423\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.641202\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.519663\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.495174\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.727258\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.529977\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.707204\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.538192\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.682305\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.465914\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.610289\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.534026\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.468615\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.716461\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.613722\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.454576\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.605050\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.538402\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.567991\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.869306\n",
      "\n",
      "Test set: Average loss: 0.2543, Accuracy: 9285/10000 (93%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.453840\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.467892\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.543353\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.497665\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.575853\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.417454\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.475249\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.565736\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.502880\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.785196\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.402846\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.311063\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.253415\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.284970\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.483889\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.456932\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.604807\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.354645\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.335326\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.289762\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.503111\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.525273\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.325215\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.321627\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.362339\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.472909\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.379403\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.532507\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.448090\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.809860\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.525359\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.376078\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.429926\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.526755\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.580987\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.593641\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.316654\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.537190\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.433533\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.629211\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.366380\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.420223\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.462738\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.465662\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.371724\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.330457\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.398483\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.575925\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.231760\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.395457\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.358299\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.298069\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.289834\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.412690\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.661084\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.426444\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.305830\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.457624\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.372957\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.495317\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.252548\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.613486\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.482103\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.283475\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.409482\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.503705\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.300239\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.336252\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.498287\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.389402\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.288032\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.445660\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.431443\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.228224\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.368141\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.546795\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.316240\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.213737\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.245797\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.289183\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.325565\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.627810\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.363024\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.379972\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.500101\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.338711\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.581923\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.376038\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.365744\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.445777\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.424100\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.713951\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.403553\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.366638\n",
      "\n",
      "Test set: Average loss: 0.1894, Accuracy: 9479/10000 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3, 1,1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, 1,1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(12544*4, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        target=target.long()\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            target=target.long()\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            data, target = data.to(\"cpu\"), target.to(\"cpu\")\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def main():\n",
    "    batch_size=64\n",
    "    test_batch_size=1000\n",
    "    epochs=3\n",
    "    lr=1\n",
    "    gamma=0.7\n",
    "    no_cuda=False\n",
    "    seed=1\n",
    "    log_interval=10\n",
    "    save_model=False\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    kwargs = {'num_workers': 0, 'pin_memory': True} if use_cuda else {}\n",
    "    \n",
    "    data_test=GridDataset('test')\n",
    "    data_train=GridDataset('train')\n",
    "    train_loader=torch.utils.data.DataLoader(data_train,batch_size=batch_size,shuffle=True, **kwargs)\n",
    "    test_loader=torch.utils.data.DataLoader(data_test,batch_size=test_batch_size,shuffle=True, **kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(log_interval, model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "am=main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda =torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "te=1\n",
    "if te==1:\n",
    "    data_test=GridDataset('test')\n",
    "    bm=torch.utils.data.DataLoader(data_test,batch_size=20,shuffle=True)\n",
    "for data,label in bm:\n",
    "    am.eval()\n",
    "    data,label=data.to(device), label.to(device)\n",
    "    x1=am.conv1(data)\n",
    "    x1=F.relu(x1) # The first covolutional layer \n",
    "    x2 = am.conv2(x1)\n",
    "    x2 = F.relu(x2) #The second convolutional layer\n",
    "    break\n",
    "x1=x1.to('cpu').detach().numpy()\n",
    "x2=x2.to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "co1=np.zeros((3136,3136))\n",
    "for i in range(3136):\n",
    "    for j in range(i,3136):\n",
    "        a=math.floor(i/56)\n",
    "        b=i%56\n",
    "        if i==j:\n",
    "            co1[i][i]=0\n",
    "        else:\n",
    "            a1=math.floor(j/56)\n",
    "            b1=j%56\n",
    "            q=math.sqrt((a-a1)*(a-a1)+(b-b1)*(b-b1))\n",
    "            co1[i][j]=q/77.78\n",
    "            co1[j][i]=q/77.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ot\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "g=20\n",
    "va1=np.zeros((64,g,g))\n",
    "for i in range(g):\n",
    "    for j in range(i,g):\n",
    "        if i==j:\n",
    "            va1[:,i,j]=0\n",
    "        else:\n",
    "            e=x1[i].reshape((64,56,56)).astype('float64')\n",
    "            f=x1[j].reshape((64,56,56)).astype('float64')\n",
    "            print(i,j);\n",
    "            for k in range(64):\n",
    "                dis=ot.sinkhorn2(e[k].reshape((3136))/(np.sum(e[k].reshape((3136)),axis=0)),f[k].reshape((3136))/(np.sum(f[k].reshape((3136)),axis=0)),co1,10^-3);\n",
    "                va1[k][i][j]=dis\n",
    "                va1[k][j][i]=dis\n",
    "va2=np.zeros((64,g,g))\n",
    "for i in range(g):\n",
    "    for j in range(i,g):\n",
    "        if i==j:\n",
    "            va2[:,i,j]=0\n",
    "        else:\n",
    "            print(i,j)\n",
    "            e=x2[i].reshape((64,56,56)).astype('float64')\n",
    "            f=x2[j].reshape((64,56,56)).astype('float64')\n",
    "            \n",
    "            for k in range(64):\n",
    "                dis=ot.sinkhorn2(e[k].reshape((3136))/(np.sum(e[k].reshape((3136)),axis=0)),f[k].reshape((3136))/(np.sum(f[k].reshape((3136)),axis=0)),co1,10^-3);\n",
    "                va2[k][i][j]=dis\n",
    "                va2[k][j][i]=dis\n",
    "va1=np.sum(va1,axis=0)/64 #averaging it between the number of channels\n",
    "va2=np.sum(va2,axis=0)/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a=np.zeros((10,10))\n",
    "b=np.zeros((10,10))\n",
    "for i in range(g):\n",
    "    for j in range(i,g):\n",
    "        a[int(label[j])][int(label[i])]+=va1z[int(label[j])][int(label[i])]\n",
    "        b[int(label[j])][int(label[i])]+=1\n",
    "        if label[i]!=label[j]:\n",
    "            a[int(label[i])][int(label[j])]+=va1z[int(label[i])][int(label[j])]\n",
    "            b[int(label[i])][int(label[j])]+=1\n",
    "z1=a/b # the average of these distances\n",
    "a=np.zeros((10,10))\n",
    "b=np.zeros((10,10))\n",
    "for i in range(g):\n",
    "    for j in range(i,g):\n",
    "        a[int(label[j])][int(label[i])]+=va2z[int(label[j])][int(label[i])]\n",
    "        b[int(label[j])][int(label[i])]+=1\n",
    "        if label[i]!=label[j]:\n",
    "            a[int(label[i])][int(label[j])]+=va2z[int(label[i])][int(label[j])]\n",
    "            b[int(label[i])][int(label[j])]+=1\n",
    "z2=a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x=[0,1,2,3,4,5,6,7,8,9]\n",
    "y=np.zeros((10))\n",
    "for i in range(16):\n",
    "    y[int(label[i])]+=1\n",
    "plt.bar(x,y)\n",
    "plt.title('Distribution of characters in the batch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.plot(x,z1[i])\n",
    "    plt.title('exact OT distances of character '+str(i)+' at the first conv layer')\n",
    "    plt.show()\n",
    "    plt.plot(x,z2[i])\n",
    "    plt.title('exact OT distances of character '+str(i)+' at the second conv layer')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ot\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "g=16\n",
    "va1z=np.zeros((64,g,g))\n",
    "for i in range(g):\n",
    "    for j in range(i,g):\n",
    "        if i==j:\n",
    "            va1z[:,i,j]=0\n",
    "        else:\n",
    "            e=x1[i].reshape((64,56,56)).astype('float64')\n",
    "            f=x1[j].reshape((64,56,56)).astype('float64')\n",
    "            print(i,j);\n",
    "            for k in range(64):\n",
    "                dis=ot.emd2(e[k].reshape((3136))/(np.sum(e[k].reshape((3136)),axis=0)),f[k].reshape((3136))/(np.sum(f[k].reshape((3136)),axis=0)),co1);\n",
    "                va1z[k][i][j]=dis\n",
    "                va1z[k][j][i]=dis\n",
    "va2z=np.zeros((64,g,g))\n",
    "for i in range(g):\n",
    "    for j in range(i,g):\n",
    "        if i==j:\n",
    "            va2z[:,i,j]=0\n",
    "        else:\n",
    "            print(i,j)\n",
    "            e=x2[i].reshape((64,56,56)).astype('float64')\n",
    "            f=x2[j].reshape((64,56,56)).astype('float64')\n",
    "            \n",
    "            for k in range(64):\n",
    "                dis=ot.emd2(e[k].reshape((3136))/(np.sum(e[k].reshape((3136)),axis=0)),f[k].reshape((3136))/(np.sum(f[k].reshape((3136)),axis=0)),co1);\n",
    "                va2z[k][i][j]=dis\n",
    "                va2z[k][j][i]=dis\n",
    "va1z=np.sum(va1z,axis=0)/64 #averaging it between the number of channels\n",
    "va2z=np.sum(va2z,axis=0)/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va1z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va2z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(x1,x2,co1,l):\n",
    "    m=np.zeros((1,64,3136,3136))\n",
    "    va1=np.zeros((64,2,2))\n",
    "    z=0\n",
    "    for i in range(2):\n",
    "        for j in range(i,2):\n",
    "            if i==j:\n",
    "                va1[:,i,j]=0\n",
    "            else:\n",
    "                e=x1[i].reshape((64,56,56)).astype('float64')\n",
    "                f=x1[j].reshape((64,56,56)).astype('float64')\n",
    "\n",
    "                for k in range(64):\n",
    "                    sq=e[k].reshape((3136))/(np.sum(e[k].reshape((3136)),axis=0))\n",
    "                    dis=ot.emd2(sq,f[k].reshape((3136))/(np.sum(f[k].reshape((3136)),axis=0)),co1)\n",
    "                    mt=ot.emd(e[k].reshape((3136))/(np.sum(e[k].reshape((3136)),axis=0)),f[k].reshape((3136))/(np.sum(f[k].reshape((3136)),axis=0)),co1)\n",
    "                    m[z,k,:,:]=proc(mt,sq)\n",
    "                    va1[k][i][j]=dis\n",
    "                    va1[k][j][i]=dis\n",
    "                z+=1\n",
    "    va2=np.zeros((64,2,2))\n",
    "    va2m1=np.zeros((64,2,2))\n",
    "    z=0\n",
    "    for i in range(2):\n",
    "        for j in range(i,2):\n",
    "            if i==j:\n",
    "                va2[:,i,j]=0\n",
    "            else:\n",
    "                e=x2[i].reshape((64,56,56)).astype('float64')\n",
    "                f=x2[j].reshape((64,56,56)).astype('float64')\n",
    "                #print(1)\n",
    "                for k in range(64):\n",
    "                    sq=e[k].reshape((3136))/(np.sum(e[k].reshape((3136))))\n",
    "                    io=f[k].reshape((3136))/(np.sum(f[k].reshape((3136))))\n",
    "                    d1=np.matmul((m[z,k,:,:].reshape((3136,3136))).T,sq).astype('float64')\n",
    "                    dis=ot.emd2(sq,io,co1)\n",
    "                    mt=ot.emd(sq,io,co1)\n",
    "                    dism1=ot.emd2(d1,io,co1)\n",
    "                    va2[k][i][j]=dis\n",
    "                    va2[k][j][i]=dis\n",
    "                    va2m1[k][i][j]=dism1\n",
    "                    va2m1[k][j][i]=dism1\n",
    "                z+=1\n",
    "    va1=np.sum(va1,axis=0)/64 #averaging it between the number of channels\n",
    "    va2=np.sum(va2,axis=0)/64\n",
    "    va2m1=np.sum(va2m1,axis=0)/64\n",
    "    l.append((va1,va2,va2m1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush Shrivastav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "C:\\Users\\Ayush Shrivastav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Ayush Shrivastav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Ayush Shrivastav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\Ayush Shrivastav\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "import ot\n",
    "use_cuda =torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "te=1\n",
    "i=0\n",
    "l=[]\n",
    "if te==1:\n",
    "    data_test=GridDataset('test')\n",
    "    bm=torch.utils.data.DataLoader(data_test,batch_size=2,shuffle=True)\n",
    "for data,label in bm:\n",
    "    am.eval()\n",
    "    data,label=data.to(device), label.to(device)\n",
    "    x1=am.conv1(data)\n",
    "    x1=F.relu(x1) # The first covolutional layer \n",
    "    x2 = am.conv2(x1)\n",
    "    x2 = F.relu(x2) #The second convolutional layer\n",
    "    x1=x1.to('cpu').detach().numpy()\n",
    "    x2=x2.to('cpu').detach().numpy()\n",
    "    data, label = data.to(\"cpu\"), label.to(\"cpu\")\n",
    "    if i>=1:\n",
    "        break\n",
    "    print(i)\n",
    "    distances(x1,x2,co1,l)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    print(label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=data.to(\"cpu\").numpy()\n",
    "\n",
    "plt.imshow(z[14][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc(m,eq):\n",
    "    for i in range(int(eq.size)):\n",
    "        if eq[i]!=0:\n",
    "            m[i,:]=m[i,:]/eq[i] \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.zeros((2,2))\n",
    "b=np.zeros((2,2))\n",
    "c=np.zeros((2,2))\n",
    "for i in range(1):\n",
    "    a1,b1,c1=l[i]\n",
    "    a+=a1\n",
    "    b+=b1\n",
    "    c+=c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.23504981],\n",
       "       [0.23504981, 0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.00162735],\n",
       "       [0.00162735, 0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.10181321],\n",
       "       [0.10181321, 0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
